#!/usr/bin/env python3
"""
Script de scraping para ebooks de MediaMarkt con actualizaci√≥n en Google Drive
EXACTLY matches the old notebook scraping logic
"""

import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from datetime import datetime
import time
import os
import math
import re
import sys
import io
import json

# ============================================
# CONFIGURACI√ìN DE GOOGLE DRIVE
# ============================================

def configurar_google_drive():
    """
    Configura y autentica con Google Drive usando credenciales de servicio
    """
    try:
        from google.oauth2 import service_account
        from googleapiclient.discovery import build
        from googleapiclient.http import MediaIoBaseUpload, MediaIoBaseDownload
        
        # Verificar si hay credenciales disponibles
        credenciales_json = os.environ.get('GOOGLE_CREDENTIALS_JSON')
        
        if not credenciales_json:
            print("‚ö†Ô∏è  No se encontraron credenciales de Google Drive en variables de entorno")
            return None
        
        # Crear credenciales desde JSON string
        creds_dict = json.loads(credenciales_json)
        scopes = ['https://www.googleapis.com/auth/drive']
        
        credentials = service_account.Credentials.from_service_account_info(
            creds_dict, scopes=scopes
        )
        
        # Crear servicio de Google Drive
        service = build('drive', 'v3', credentials=credentials)
        
        print("‚úÖ Google Drive configurado exitosamente")
        return service
        
    except ImportError:
        print("‚ùå M√≥dulos de Google API no instalados. Instala: pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib")
        return None
    except Exception as e:
        print(f"‚ùå Error configurando Google Drive: {e}")
        return None

def buscar_archivo_drive(service, nombre_archivo, folder_id):
    """
    Busca un archivo en Google Drive
    """
    try:
        query = f"name = '{nombre_archivo}' and '{folder_id}' in parents and trashed = false"
        results = service.files().list(
            q=query,
            fields="files(id, name, modifiedTime)"
        ).execute()
        
        files = results.get('files', [])
        return files[0] if files else None
        
    except Exception as e:
        print(f"‚ùå Error buscando archivo en Drive: {e}")
        return None

def descargar_archivo_drive(service, file_id):
    """
    Descarga un archivo de Google Drive
    """
    try:
        request = service.files().get_media(fileId=file_id)
        fh = io.BytesIO()
        downloader = MediaIoBaseDownload(fh, request)
        
        done = False
        while not done:
            status, done = downloader.next_chunk()
        
        fh.seek(0)
        return fh.getvalue().decode('utf-8')
        
    except Exception as e:
        print(f"‚ùå Error descargando archivo de Drive: {e}")
        return None

def subir_archivo_drive(service, nombre_archivo, contenido, folder_id, file_id=None):
    """
    Sube o actualiza un archivo en Google Drive
    """
    try:
        from googleapiclient.http import MediaIoBaseUpload
        
        file_metadata = {
            'name': nombre_archivo,
            'parents': [folder_id]
        }
        
        media = MediaIoBaseUpload(
            io.BytesIO(contenido.encode('utf-8')),
            mimetype='text/csv',
            resumable=True
        )
        
        if file_id:
            # Actualizar archivo existente
            archivo = service.files().update(
                fileId=file_id,
                media_body=media
            ).execute()
            print(f"‚úÖ Archivo actualizado en Google Drive: {archivo.get('name')}")
        else:
            # Crear nuevo archivo
            archivo = service.files().create(
                body=file_metadata,
                media_body=media,
                fields='id'
            ).execute()
            print(f"‚úÖ Nuevo archivo creado en Google Drive: {nombre_archivo}")
        
        return archivo
        
    except Exception as e:
        print(f"‚ùå Error subiendo archivo a Drive: {e}")
        return None

def actualizar_csv_drive(df_nuevo, folder_id="17jYoslfZdmPgvbO2JjEWazHmS4r79Lw7", nombre_archivo="ebooks_mediamarkt.csv"):
    """
    Actualiza un archivo CSV en Google Drive combinando datos existentes con nuevos
    NO elimina duplicados entre d√≠as diferentes - conserva historial diario
    """
    print("\n" + "="*60)
    print("ACTUALIZANDO GOOGLE DRIVE")
    print("="*60)
    
    # Configurar Google Drive
    service = configurar_google_drive()
    if not service:
        print("‚ö†Ô∏è  Omitiendo actualizaci√≥n en Google Drive")
        return False
    
    try:
        # Buscar archivo existente
        archivo_existente = buscar_archivo_drive(service, nombre_archivo, folder_id)
        
        if archivo_existente:
            print(f"üìÅ Archivo encontrado en Drive: {archivo_existente['name']}")
            print(f"üìÖ √öltima modificaci√≥n: {archivo_existente.get('modifiedTime', 'Desconocida')}")
            
            # Descargar archivo existente
            contenido_existente = descargar_archivo_drive(service, archivo_existente['id'])
            
            if contenido_existente:
                # Leer CSV existente
                df_existente = pd.read_csv(io.StringIO(contenido_existente))
                print(f"üìä Registros existentes en Drive: {len(df_existente)}")
                
                # Verificar si hay columnas comunes
                columnas_existente = set(df_existente.columns)
                columnas_nuevo = set(df_nuevo.columns)
                
                # Encontrar columnas comunes
                columnas_comunes = list(columnas_existente & columnas_nuevo)
                
                if columnas_comunes:
                    print(f"üìã Columnas comunes: {columnas_comunes}")
                    
                    # Seleccionar solo columnas comunes de ambos DataFrames
                    df_existente_compatible = df_existente[columnas_comunes]
                    df_nuevo_compatible = df_nuevo[columnas_comunes]
                    
                    # COMBINAR sin eliminar duplicados entre d√≠as diferentes
                    # Solo eliminar duplicados EXACTOS (mismos datos en todas las columnas)
                    df_combinado = pd.concat([df_existente_compatible, df_nuevo_compatible], ignore_index=True)
                    
                    # ELIMINAR SOLO duplicados exactos (mismo producto, precio y fecha)
                    # Esto evita duplicados de la MISMA ejecuci√≥n
                    duplicados_exactos = df_combinado.duplicated(keep='first').sum()
                    df_combinado = df_combinado.drop_duplicates(keep='first')
                    
                    print(f"üóëÔ∏è  Duplicados exactos eliminados: {duplicados_exactos}")
                    print(f"üìà Registros despu√©s de combinar: {len(df_combinado)}")
                    print(f"‚ûï Nuevos registros a√±adidos: {len(df_nuevo)}")
                    
                    # Calcular cu√°ntos registros son de hoy
                    fecha_hoy = datetime.now().strftime("%Y-%m-%d")
                    registros_hoy = df_combinado[df_combinado['fecha_extraccion'].str.contains(fecha_hoy)].shape[0]
                    print(f"üìÖ Registros de hoy ({fecha_hoy}): {registros_hoy}")
                    
                else:
                    print("‚ö†Ô∏è  No hay columnas comunes entre los DataFrames")
                    print(f"  Columnas existentes: {list(columnas_existente)}")
                    print(f"  Columnas nuevas: {list(columnas_nuevo)}")
                    df_combinado = df_nuevo
            else:
                print("‚ö†Ô∏è  No se pudo descargar el archivo existente, creando uno nuevo")
                df_combinado = df_nuevo
        else:
            print("üìù No se encontr√≥ archivo existente, creando uno nuevo")
            df_combinado = df_nuevo
        
        # Convertir DataFrame combinado a CSV
        csv_contenido = df_combinado.to_csv(index=False, encoding='utf-8')
        
        # Subir/actualizar archivo en Drive
        file_id = archivo_existente['id'] if archivo_existente else None
        archivo = subir_archivo_drive(service, nombre_archivo, csv_contenido, folder_id, file_id)
        
        if archivo:
            print(f"‚úÖ Google Drive actualizado exitosamente")
            print(f"üìä Total de registros en archivo combinado: {len(df_combinado)}")
            
            # Estad√≠sticas adicionales
            if 'fecha_extraccion' in df_combinado.columns:
                fechas_unicas = df_combinado['fecha_extraccion'].str[:10].nunique()
                print(f"üìÖ D√≠as diferentes en el dataset: {fechas_unicas}")
                
                # Mostrar distribuci√≥n por fecha
                print("\nüìä Distribuci√≥n por fecha:")
                distribucion = df_combinado['fecha_extraccion'].str[:10].value_counts().sort_index()
                for fecha, cantidad in distribucion.items():
                    print(f"  {fecha}: {cantidad} registros")
            
            return True
        else:
            print("‚ùå Error actualizando Google Drive")
            return False
            
    except Exception as e:
        print(f"‚ùå Error en el proceso de Google Drive: {e}")
        import traceback
        traceback.print_exc()
        return False

# ============================================
# FUNCIONES DE SCRAPING (EXACTLY like old notebook)
# ============================================

def setup_chrome_options():
    """Configura Chrome para ejecuci√≥n headless (optimizado)"""
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument(""--disable-dev-shm-usage")
    chrome_options.add_argument(""--disable-gpu")
    chrome_options.add_argument(""--window-size=1920,1080")
    chrome_options.add_argument(""--disable-blink-features=AutomationControlled")
    chrome_options.add_argument(""--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36")
    
    # Deshabilitar im√°genes para acelerar
    prefs = {"profile.managed_default_content_settings.images": 2}
    chrome_options.add_experimental_option("prefs", prefs)
    
    return chrome_options

def mediamark_mob_(url):
    """Inicializa el navegador Chrome - EXACTLY like old notebook"""
    try:
        chrome_options = setup_chrome_options()
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=chrome_options)
        
        driver.get(url)
        # Removed maximize_window for headless
        time.sleep(2)

        # Aceptar cookies
        try:
            aceptar = driver.find_element(By.ID, "pwa-consent-layer-accept-all-button")
            aceptar.click()
            print("Cookies aceptadas")
        except Exception as e:
            print(f"Error aceptando cookies: {e}")

        time.sleep(3)
        
        return driver
        
    except Exception as e:
        print(f"‚ùå Error inicializando Chrome: {e}")
        raise

def obtener_total_articulos(driver):
    """
    Obtiene el n√∫mero total de art√≠culos del span y calcula las p√°ginas necesarias
    EXACTLY like old notebook
    """
    try:
        # Buscar el elemento que contiene el total de art√≠culos
        elemento_total = driver.find_element(By.CSS_SELECTOR, 'span.sc-94eb08bc-0.AKpzk')
        texto_total = elemento_total.text
        
        # Extraer solo los n√∫meros del texto (ej: "(3866 art√≠culos)" -> 3866)
        numero_total = re.search(r'\((\d+)', texto_total)
        
        if numero_total:
            total_articulos = int(numero_total.group(1))
            print(f"üìä Total de art√≠culos encontrados: {total_articulos}")
            
            # Calcular n√∫mero de p√°ginas necesarias (cada p√°gina muestra 12 productos)
            productos_por_pagina = 12
            total_paginas = math.ceil(total_articulos / productos_por_pagina)
            print(f"üìÑ Total de p√°ginas a recorrer: {total_paginas}")
            
            return total_articulos, total_paginas
        else:
            print("‚ùå No se pudo extraer el n√∫mero total de art√≠culos")
            return None, 10  # Valor por defecto
    
    except Exception as e:
        print(f"‚ùå Error obteniendo el total de art√≠culos: {e}")
        return None, 10  # Valor por defecto en caso de error

def extraer_precio_producto(contenedor_producto):
    """
    Funci√≥n espec√≠fica para extraer el precio correcto de un producto
    Prioriza el precio final sobre el precio original tachado
    EXACTLY like old notebook
    """
    try:
        # PRIMERO: Buscar precio final (rebajado) - span con clase dYbTef
        try:
            precio_final = contenedor_producto.find_element(By.CSS_SELECTOR, 'span.sc-94eb08bc-0.dYbTef.sc-8a3a8cd8-2.csCDkt')
            return precio_final.text
        except:
            pass
        
        # SEGUNDO: Buscar precio normal - span con clase OhHlB
        try:
            precio_normal = contenedor_producto.find_element(By.CSS_SELECTOR, 'span.sc-94eb08bc-0.OhHlB.sc-8a3a8cd8-2.csCDkt')
            return precio_normal.text
        except:
            pass
        
        # TERCERO: Buscar cualquier precio que contenga ‚Ç¨
        try:
            elementos_precio = contenedor_producto.find_elements(By.XPATH, ".//*[contains(text(), '‚Ç¨')]")
            for elem in elementos_precio:
                texto = elem.text.strip()
                if '‚Ç¨' in texto and any(c.isdigit() for c in texto):
                    return texto
        except:
            pass
        
        return "Precio no disponible"
        
    except Exception as e:
        return f"Error: {e}"

def extraer_productos_pagina(driver):
    """
    Extrae los productos de una sola p√°gina
    EXACTLY like old notebook
    """
    productos_pagina = []
    
    try:
        # Buscar todos los t√≠tulos de productos en la p√°gina actual
        productos_titulos = driver.find_elements(By.CSS_SELECTOR, 'p[data-test="product-title"]')
        
        print(f"   üîç Encontrados {len(productos_titulos)} productos en la p√°gina")
        
        # Para cada t√≠tulo, encontrar su contenedor y extraer informaci√≥n
        for i, titulo in enumerate(productos_titulos):
            try:
                # Encontrar el contenedor del producto
                contenedor = titulo
                for _ in range(5):
                    contenedor = contenedor.find_element(By.XPATH, "./..")
                    try:
                        precios = contenedor.find_elements(By.XPATH, ".//*[contains(text(), '‚Ç¨')]")
                        if precios:
                            break
                    except:
                        continue
                
                # Extraer nombre y precio
                nombre = titulo.text
                precio = extraer_precio_producto(contenedor)
                
                productos_pagina.append({
                    'nombre': nombre,
                    'precio': precio
                })
                
            except Exception as e:
                print(f"   ‚ùå Error extrayendo producto {i+1} de la p√°gina: {e}")
                continue
                
        return productos_pagina
        
    except Exception as e:
        print(f"‚ùå Error extrayendo productos de la p√°gina: {e}")
        return productos_pagina

def extraer_productos(driver):
    """
    Extrae todos los productos
    EXACTLY like old notebook - 5 sorting criteria, 30 pages each
    """
    # Lista para almacenar todos los productos
    productos_data = []
    contador_global = 1
    
    try:
        # OBTENER TOTAL DE ART√çCULOS
        total_articulos, total_paginas = obtener_total_articulos(driver)
        
        print(f"üîÑ Total de art√≠culos: {total_articulos}")
        print(f"üìÑ P√°ginas calculadas: {total_paginas}")
        
        # Diferentes criterios de ordenaci√≥n para obtener todos los productos
        criterios_ordenacion = [
            "currentprice+desc",    # Precio descendente
            "currentprice+asc",     # Precio ascendente  
            "relevance",            # Relevancia
            "name+asc",             # Nombre A-Z
            "name+desc"             # Nombre Z-A
        ]
        
        productos_unicos = set()
        
        for criterio in criterios_ordenacion:
            print(f"üéØ Usando criterio de ordenaci√≥n: {criterio}")
            
            for pagina in range(1, 31):  # M√°ximo 30 p√°ginas por criterio
                try:
                    print(f"üìñ P√°gina {pagina}/30 - Criterio: {criterio}")
                    
                    # URL de ebooks
                    url_pagina = f"https://www.mediamarkt.es/es/category/ebooks-249.html?sort={criterio}&page={pagina}"
                    
                    # Navegar a la p√°gina
                    driver.get(url_pagina)
                    
                    # Esperar a que cargue la p√°gina - EXACT timing
                    time.sleep(2)
                    
                    # Verificar que la p√°gina carg√≥ correctamente
                    try:
                        WebDriverWait(driver, 10).until(
                            EC.presence_of_element_located((By.CSS_SELECTOR, 'p[data-test="product-title"]'))
                        )
                    except:
                        print(f"‚ùå La p√°gina {pagina} no carg√≥ correctamente, pasando a siguiente criterio")
                        break
                    
                    # Extraer productos de la p√°gina actual
                    productos_pagina = extraer_productos_pagina(driver)
                    
                    # Agregar solo productos nuevos
                    for producto in productos_pagina:
                        nombre_producto = producto['nombre']
                        if nombre_producto not in productos_unicos:
                            productos_unicos.add(nombre_producto)
                            producto['numero'] = contador_global
                            contador_global += 1
                            productos_data.append(producto)
                    
                    print(f"‚úÖ P√°gina {pagina}: {len(productos_pagina)} productos, Total √∫nicos: {len(productos_data)}")
                    
                    # Si la p√°gina tiene menos de 12 productos, es la √∫ltima
                    if len(productos_pagina) < 12:
                        print("üìù √öltima p√°gina detectada")
                        break
                        
                    # Peque√±a pausa entre p√°ginas - EXACT timing
                    time.sleep(1)
                    
                except Exception as e:
                    print(f"‚ùå Error en p√°gina {pagina}: {e}")
                    continue
        
        print(f"\nüìä Resumen final: {len(productos_data)} productos √∫nicos de {len(criterios_ordenacion)} criterios")
        
        if total_articulos:
            porcentaje = (len(productos_data) / total_articulos) * 100
            print(f"üìà Se extrajo el {porcentaje:.1f}% del total de art√≠culos")
        
        return productos_data
                
    except Exception as e:
        print(f"‚ùå Error extrayendo productos: {e}")
        return productos_data

def guardar_en_dataframe(productos_data):
    """
    Convierte la lista de productos en un DataFrame y lo guarda en CSV
    EXACTLY like old notebook
    """
    if not productos_data:
        print("No hay datos para guardar")
        return None
    
    # Crear DataFrame (ya vienen sin duplicados)
    df = pd.DataFrame(productos_data)
    
    # A√±adir fecha y hora de extracci√≥n
    fecha_extraccion = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    df['fecha_extraccion'] = fecha_extraccion
    
    # Reordenar columnas
    column_order = ['fecha_extraccion', 'numero', 'nombre', 'precio']
    df = df[column_order]
    
    # Crear carpeta para resultados si no existe
    os.makedirs("scraping_results", exist_ok=True)
    
    # Nombre del archivo
    nombre_archivo = f"scraping_results/ebooks_mediamarkt_completo_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
    file_path = nombre_archivo
    df.to_csv(file_path, index=False, encoding='utf-8')
    
    print(f"\n‚úÖ Datos guardados en: {file_path}")
    print(f"üìä Total de productos √∫nicos: {len(df)}")
    
    # Mostrar resumen
    productos_con_precio = len(df[df['precio'].str.contains('‚Ç¨', na=False)])
    productos_sin_precio = len(df) - productos_con_precio
    
    print(f"üí∞ Productos con precio: {productos_con_precio}")
    print(f"‚ùå Productos sin precio: {productos_sin_precio}")
    
    # Mostrar primeras filas
    print("\nüìã Primeras 5 filas del DataFrame:")
    print(df.head())
    
    return df, file_path

# ============================================
# FUNCI√ìN PRINCIPAL
# ============================================

def main():
    """Funci√≥n principal"""
    print("="*60)
    print("SCRAPING DE EBOOKS - MEDIAMARKT")
    print("="*60)
    print(f"Fecha y hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*60)
    
    driver = None
    
    try:
        # URL objetivo
        url = "https://www.mediamarkt.es/es/category/ebooks-249.html?sort=currentprice+desc"
        
        print(f"\nüåê Accediendo a: {url}")
        
        # Paso 1: Inicializar navegador
        driver = mediamark_mob_(url)
        
        # Paso 2: Extraer productos (EXACTLY like old notebook)
        productos_data = extraer_productos(driver)
        
        if not productos_data:
            print("No se extrajeron productos")
            return False
        
        # Paso 3: Guardar en DataFrame
        df, archivo_csv = guardar_en_dataframe(productos_data)
        
        if df is None:
            print("‚ùå Error creando DataFrame. Terminando ejecuci√≥n.")
            return False
        
        # Paso 4: Actualizar Google Drive con APPEND (no overwrite)
        print("\nüîÑ Actualizando Google Drive (APPEND mode)...")
        print("üìå Nota: Los datos se a√±adir√°n, NO se sobrescribir√°n")
        print("üìå Se mantendr√° el historial d√≠a a d√≠a")
        
        drive_actualizado = actualizar_csv_drive(df)
        
        if drive_actualizado:
            print("‚úÖ Google Drive actualizado exitosamente (APPEND)")
        else:
            print("‚ö†Ô∏è  No se pudo actualizar Google Drive (puede ser falta de credenciales)")
        
        print("\n" + "="*60)
        print("RESUMEN EJECUCI√ìN")
        print("="*60)
        print(f"‚úÖ Scraping completado exitosamente")
        print(f"üì¶ Productos obtenidos hoy: {len(df)}")
        print(f"üìÅ Archivo local generado: {archivo_csv}")
        print(f"üíæ Google Drive: Datos a√±adidos al archivo hist√≥rico")
        
        return True
            
    except Exception as e:
        print(f"Error en la ejecuci√≥n: {e}")
        import traceback
        traceback.print_exc()
        return False
        
    finally:
        # Cerrar el navegador
        if driver:
            try:
                driver.quit()
                print("\nüõë Navegador cerrado")
            except:
                pass
        
        print("\n" + "="*60)
        print("EJECUCI√ìN FINALIZADA")
        print("="*60)

if __name__ == "__main__":
    # Ejecutar scraping
    success = main()
    
    # Salir con c√≥digo apropiado para CI/CD
    sys.exit(0 if success else 1)
