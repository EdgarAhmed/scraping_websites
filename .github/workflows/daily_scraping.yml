name: Daily Scraping Job

on:
  schedule:
    - cron: '0 8 * * *'
  workflow_dispatch:

jobs:
  run-scraping:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.9'
        
    - name: Install Chrome
      run: |
        sudo apt-get update
        sudo apt-get install -y wget unzip gnupg
        
        # Instalar Chrome
        wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo gpg --dearmor -o /usr/share/keyrings/google-chrome-keyring.gpg
        echo "deb [arch=amd64 signed-by=/usr/share/keyrings/google-chrome-keyring.gpg] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
        sudo apt-get update
        sudo apt-get install -y google-chrome-stable
        
        google-chrome --version
        
    - name: Install Python dependencies
      run: |
        pip install --upgrade pip
        
        # Dependencias principales
        pip install selenium pandas webdriver-manager lxml
        
        # Dependencias para Google Drive API
        pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib
        
        # Si hay requirements.txt, instalarlo tambi√©n
        if [ -f "requirements.txt" ]; then
          pip install -r requirements.txt
        fi
        
    - name: Run Python scraping script
      env:
        # Variables de entorno para Chrome
        DISPLAY: :99
        PYTHONUNBUFFERED: 1
        
        # Credenciales de Google Drive (debes configurar esto en GitHub Secrets)
        GOOGLE_CREDENTIALS_JSON: ${{ secrets.GOOGLE_CREDENTIALS_JSON }}
      run: |
        echo "üìÅ Directorio de trabajo: $(pwd)"
        echo "üìÅ Contenido del directorio scraping_web/:"
        ls -la scraping_web/
        
        echo "üöÄ Iniciando scraping de ebooks de MediaMarkt..."
        echo "üîÑ Configurando Google Drive..."
        
        # Verificar si hay credenciales de Google Drive
        if [ -z "$GOOGLE_CREDENTIALS_JSON" ]; then
          echo "‚ö†Ô∏è  ADVERTENCIA: No se configuraron credenciales de Google Drive"
          echo "‚ÑπÔ∏è   El script se ejecutar√° pero no actualizar√° Google Drive"
        else
          echo "‚úÖ Credenciales de Google Drive configuradas"
        fi
        
        # Crear directorio para resultados
        mkdir -p scraping_results
        
        # Ejecutar el script
        python scraping_web/scrip_ebooks_01.py
        
        echo "‚úÖ Script ejecutado. Verificando resultados..."
        
        # Listar archivos generados
        echo "üìÑ Archivos generados:"
        ls -la scraping_results/ 2>/dev/null || echo "No hay resultados en scraping_results/"
        
    - name: Upload results as artifacts
      uses: actions/upload-artifact@v4
      with:
        name: scraping-output
        path: |
          scraping_results/*.csv
          *.csv
        retention-days: 7
        
    - name: Notify on failure
      if: failure()
      run: |
        echo "‚ùå El scraping de MediaMarkt ha fallado"
        echo "Revisa los logs para m√°s detalles"
